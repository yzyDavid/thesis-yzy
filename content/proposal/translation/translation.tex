\cleardoublepage
\chapter{外文翻译}

Large-scale cluster management at Google with Borg

Google 使用 Borg 系统进行的大规模集群管理

\section*{摘要}

Borg是谷歌内部使用的集群管理系统。在这个系统的管理之下，有数千个应用的数十万级别的任务在运行。他们横跨了多个达到上万台服务器规模的集群。

Borg通过进程级别隔离的机器资源共享，资源超卖，任务组合等方式极大地提升了资源利用率。它通过调度策略降低了应用整体故障宕机的风险，并且通过运行时的特性最小化故障恢复时间，从而为高可用应用提供可能。Borg提供了描述任务的DSL（领域专用语言），服务发现机制，实时任务监控及相关的分析工具来简化用户的操作。

本文提供了Borg系统的架构和功能的简述，同时包括了重要的设计决定和策略的分析，以及十年间使用经验留下的经验和教训。

\section{简介}

我们称之为Borg的系统负责谷歌内部所有应用的提交，调度，启动，重启与监视，下面讲解这一切是如何做到的。

Borg主要有三个优点：

1、隐藏了资源管理和故障恢复的细节，使用户可以专注于业务应用。

2、操作的可靠性和可用性高，从而使应用一样获利。

3、使任务负载可以高效地在上千台服务器的集群规模下部署。

Borg不是第一个完成这些功能的系统，但可能是唯一一个可靠性与完成度足以在如此大的规模下运行的。本文也将从这几个方面入手论述。

\section{用户的视角}

Borg 的用户是运行 Google 的应用和服务的开发者与系统管理员。用户以“工作”（job）的形式将任务提交给Borg系统，每个工作包括一个或多个运行相同应用程序（二进制）的“任务”（task）。每个工作将运行在一个“单元”（cell）当中。单元指一组行使相同职能的机器。

\subsection{工作负载}

Borg cell 运行的异质负载分为两个主要部分。首先是长期运行的服务，应该“永远”不被停止，并处理对延迟敏感的请求（几μs到几百ms）。 这些服务用于面向最终用户的产品，例如Gmail，Google Docs和网络搜索和内部基础设施服务（例如BigTable）。 第二个是从少数人那里获得的批量任务几秒到几天完成; 这些任务对短期性能波动不太敏感。任务的比例在不同的cell中各有区别，根据它们的主要租户不同，运行的业务类型区别也很大。批处理作业启启停停，许多面向终端用户的服务表现出了昼夜使用量不同的模式。这些场景Borg都能很好地处理。

\subsection{集群和单元}

属于一个单元的机器一定属于一个“集群”（cluster），属于同一集群的机器之间使用数据中心级别的高性能网络拓扑进行连接。每个集群存在于一个单独的数据中心当中，多个数据中心的多个集群可以构成 Google 规模的网站。一般来讲一个集群当中有一个规模很大的单元，可能还会视情况有多个实验或者测试性质的小单元或者特殊用途的单元。我们在孜孜不倦地避免任何单点故障的风险。

我们的一个典型中等规模单元往往包含一万台服务器左右，部分大的单元规模远大于此。单元中的服务器在各个维度上都可以是异质的，包括 CPU，网络，磁盘和内存的大小，处理器种类，性能或者存储设备类型，外部IP地址等其他资源。Borg通过将任务分配在不同的单元中来为用户隔离几乎所有资源，为用户分配资源，安装程序和依赖，使应用运行并监控它的健康度，以随时重启一个崩溃的进程。

\subsection{工作（jobs）和任务（tasks）}

每个Borg工作的属性包括名字，所有者和包含的任务的数目。工作可以具有约束（constraints）来限定可以运行它的任务的机器，机器通过特性（attributes）来描述可以承载的约束。这些特性可以包括处理器价格，操作系统版本和外部IP地址。约束可以是“软”的或者“硬”的，软的约束更像是偏好，硬的约束则必须被满足。工作的启动可以被排在上一个相同工作之后，每个工作仅运行在一个单元当中。

每个任务对应为运行在一台机器的一个容器中的一组进程。我们不想为虚拟化付出额外的代价，所以Borg的绝大多数负载都不会运行在虚拟机当中。同时也因为，设计这个系统的时候，我们投入了大量精力考虑使用没有虚拟化支持的处理器硬件。

任务当然也有自己的属性。这包括了资源的需求以及任务在工作中的序号。大部分任务的属性应该是一致的，但是用户也可以不这样做。我们不强制要求资源大小固定的“桶”或者“槽”。Borg上面运行的程序尽可能静态链接以减少依赖，同时将二进制与数据文件打包，由Borg统一编排安装过程。

用户通过远程过程调用（RPC）的方式来向Borg提交任务。这可以通过命令行工具，管理界面或者其他Borg工作来自动实现。Borg有一种GCL语言的变种，称为BCL，来声明式地描述用户需要的配置。

用户随时可以提交一个工作的新配置来升级替换掉之前的配置，Borg会在下一轮调度时更改这个配置。根据你修改的配置，比如二进制变更，资源变更等等，Borg可能会重启你的进程或者迁移它到其他机器去执行，否则升级过程不会使人感知到。在调度操作抢占一个任务之前，UNIX SIGTERM 信号可能会发出，提示进程进行清理操作。尽管不能保证这个信号一定来得及发出或者被处理。

\subsection{分配（Alloc）}

这里的分配是一种预先抢占资源留给特定任务使用的概念。任务可以运行在一组预分配的资源上面，也可以用来限制不同的任务工作在相同的机器上。这里有一个例子。我们有两个任务，其一是一个Web服务器，其二是收集访问这个Web服务的URL（访问日志）上传到分布式文件系统以供后来分析的daemon。我们如果设计一个虚拟的alloc供这两个任务使用，他们自然就会工作在相同的机器上面了。

\subsection{优先级，配额和权限管理}

当用户们提交的总工作量超过了集群的负载能力时会发生什么？我们给出的答案是优先级（Priority）和配额（Quota）。每个工作都有自己的优先级，使用一个小的正整数表达。高优先级的任务索取资源，即使需要终止低优先级的任务工作也在所不惜。Borg定义了几个相互不重叠的优先级范围，由高到低排列包括：监控（monitoring）生产（production）批处理（batch）和尽力而为（best offort）。本文论述的生产任务包括最高的两个优先级。

为了防止细微的优先级差异导致互相争抢资源，高优先级的进程一点点挤走低优先级，链式反应，触发大量重新调度，我们不允许生产级别的进程之间抢占。尽管如此，优先级的细微区别还是会对稳定性有帮助，举个例子，将MapReduce任务的管理者进程优先级设置到略微高于工作者进程有助于提高整个MapReduce任务的稳定性。

优先级表达了工作之间的相对重要性，而配额则用来决定一个工作能否被提交。

\subsection{命名与监控}

\section{Borg架构}

Borg单元由一组机器，一个称为Borgmaster的逻辑集中控制器和一个代理程序组成，称为Borglet，它在一个单元格中的每台机器上运行。 Borg的所有组件都是用 C++ 编写的。

\section{可用性}

失败是大规模系统的常态，图3提供了15个样本单元上的故障原因分析。 预计在Borg上运行的应用程序使用多副本等技术处理此类事件，将持久状态存储在分布式文件系统中，并且（如果适当的）偶尔记录检查点。 即便如此，我们也会尝试减轻这些事件的影响。

\section{利用率}

Borg的主要目标之一是有效利用谷歌的机器舰队，在如此之大的机器金融投资面前，提高利用率几个百分点可以节省数百万美元。 本节讨论并评估一些Borg采用的策略和技术。

\section{隔离}

我们50％的机器运行9个或更多任务; 大约90％的机器有大约25个任务，将运行大约4500个线程。 尽管在应用程序之间共享计算机可以提高利用率，但它还需要良好的机制来防止任务相互干扰。 这同时对于安全性和性能都有价值。

\section{相关工作与引用}

资源调度这个话题已经被研究了数十年了，涉及的领域包括高性能计算（网格计算），工作站网络和服务器集群。我们这里列出一些和Borg场景最接近的，也即服务器集群相关的工作和研究。下面列出一些已知的开源软件和内部系统。

\subsection{Apache Mesos}

它的设计分离了资源管理和分配放置功能，资源管理是中心化的而调度分配有框架化的实现。

\subsection{Apache YARN}

Apache YARN是Hadoop生态中的调度系统。

\subsection{Facebook Tupperware}

Tupperware公开的细节不多，比较接近Borg。

\subsection{Microsoft Autopilot}

此系统运行了微软的软件监视，部署和维护功能。

\subsection{Alibaba Fuxi}

伏羲系统支持了数据分析类的负载，其调度思路与Borg有所不同。 
