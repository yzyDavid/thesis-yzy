\cleardoublestylepage{common}

\section{正文}

\subsection{目标}

本部分描述本设计所开发的系统的功能与目的。

\subsubsection{背景与趋势}

\subsubsection{问题与解决方案}

\subsection{开发技术}

本部分列出工程实现上所依赖的全部技术。

golang v1.11.5

GoLand 2019.1.1

Kubernetes v1.14

minikube 1.0.0

operator-framework v1.0.0

\subsection{工程背景}

本部分将会论述为了实现本系统，依赖的开源组件与开源解决方案等。

\subsubsection{Kubernetes}

Kubernetes （下文中可能简称为k8s）是由云原生基金会所维护的项目，其设计思想脱胎于 Google 内部使用的 Borg 集群管理系统。Kubernetes 借助于容器的实现，负责容器编排与资源调度分配。Kubernetes 的概念与所包含的组件在下文中详细介绍，通过这段说明可以使读者更容易理解如此一个容器编排系统负责了什么工作，解决了什么问题。

\subsubsection{Tensorflow Serving}

Tensorflow 是近年来生态最完善的深度学习框架之一，从其工作方式来看，也可以被称为计算图框架。其深度学习相关的部分我们不在这里做过多讨论，有很丰富的资料，感兴趣的读者可以自行查阅。这里我们介绍一下 Tensorflow Serving，这个负责使用训练好的模型的组件，其工作方式，与容器生态的关系，最终得出为何用它作为本设计中的代表应用的例子。

Tensorflow Serving 可以将 Tensorflow 训练得到的模型，注意默认支持 saved model 格式的模型，对 tensorflow 产出训练结果有了解的读者应当知道其中差别。

用户运行 Tensorflow Serving 时，通过命令行参数或者环境变量等等方式传递模型的名称，路径等参数，不需要修改源代码或者编写更多的代码就可以使模型上线服务，这样可以做到模型数据和逻辑的分离，对方便使用，加快部署迭代速度有帮助。

Tensorflow Serving 非常注重面向容器的生态，不难得出结论，只需提供模型的数据文件，就可以被加载服务，这说明 Tensorflow Serving 属于带数据的只读服务。结果上，Tensorflow Serving 官方将 docker image 作为比二进制更重要的发布渠道，用户通过 docker registry pull 合适版本的 Serving 镜像，就可以直接使用，无疑是更方便运维，对比与使用的。这也是我选择使用 Tensorflow Serving 作为示例应用，进行对它的调度算法实验，开发的重要原因。另一个重要原因是，作为机器学习服务，它属于业务逻辑和框架本身界限明显，明确区分，分开理解的典型代表。如果从数据/业务与框架分离的角度考虑，任何一个区分租户的数据库或搜索引擎系统也可以作为例子，但是这里他们的代表性不如机器学习服务明显，且机器学习作为相对而言的新兴事物，对它的尝试和探索更有价值。但是这不代表本设计的成果就对其他领域没有意义了，这一点还需要读者明辨。

\subsubsection{Kubernetes Operator}

Kubernetes Operator 是 Kubernetes 生态中为用户自己提供调度逻辑和功能扩展的一类接口与实现方式的总称。

\subsection{实现方式}

本部分将会详细讲解本人实现此系统的详细过程。

\subsubsection{搭建 Kubernetes 开发环境}

作为一个生产级别的容器编排系统，天然就是面向分布式系统，保证可靠性的，工作方式也需要天然面向分布式系统，为部署在多台机器上做设计。同时此系统将应用程序的运行，甚至网络环境都进行了接管，因此对运行环境有很强的依赖。实际操作上也是如此，我调研了多种搭建 Kubernetes 环境的方案，最终只有一种方式实现起来相对简单。下面概要讲解一下各种搭建方式的优劣，以及我最后的选择。

% TODO: enumerate

Kernel and Services Requirements

本部分讲解运行 Kubernetes 的机器需要满足的条件。

Kubernetes 本身需要在 Linux 服务器上运行，而 Kubernetes 本身是否运行在虚拟机当中又造成了环境需求的不一致。不过总的来讲，我们的开发环境需要满足以下这些需求就能够运行。对于内核来说，需要支持 iptables 的大部分调度算法类内核模块，以便支持 Kubernetes 网络相关的功能。需要支持 KVM，以便我们选择 KVM 作为运行 minikube 虚拟机的后端，同时需要支持 libvirt 需要的部分功能。我们还可能需要多种内核 namespace 支持，包括 mount namespace, pid namespace 等等，以及部分文件开关和杂项以便支持 docker 工作。好在编译安装 docker 与 libvirt 时，脚本会对内核选项进行校验，并输出不满足的项目。最后我们还需要 NFS 支持，如果需要像我一样使用 NFS 挂载模型数据目录的话。

这里我们假设读者有能力自行配置内核编译选项，并且编译安装内核。较为成熟的发行版往往会提供发行版官方分支的内核源码软件包供我们使用。并且我们这里要求的内核功能在主流发行版当中往往是默认开启的，这里的介绍涉及一些原理，给读者补充背景知识并且留作备用。

至于内核之外的软件包和服务，我们需要按需安装并调通 docker, libvirt, qemu-kvm 等，视用户打算采用本机方式安装或者虚拟化方式安装而定。

% TODO: from proposal

dind approach

DinD 指代 Docker in Docker。这是一种单机部署 Kubernetes 测试集群的方案，并且有人已经在 Github 上开源了一整套工具脚本和解决方案。这一方案适合于用户有能运行 Docker 的 Linux 主机，但是没有虚拟化能力。对于具有对主机的完全控制力和虚拟化能力的情况来讲，DinD 方案也可以采用，但表现不一定有官方性质维护的 minikube 效果更好，在 troubleshooting 和资料支持方面。

在此方案下，我们使用一个功能类似于 minikube 的虚拟机的 Docker 镜像，作为运行 kubernetes 集群的主机，在这个容器内运行 Kubernetes 组件的容器。这样带来的一个问题是，需要宿主机内核完全支持 kubernetes 运行需要的一切特性，且隔离程度不够，docker 版本也需要和 kubernetes 可以配合。

本人的尝试当中，DinD 镜像与容器可以启动，但是工作不完全正常，内部有 kubernetes 组件报错，最终在考量了成本和收益之后，本人选择放弃使用这个方案。

Bare Metal approach

Bare Metal 可以翻译为裸金属服务器，指没有经过任何虚拟化的裸机。这里本人使用个人电脑上安装的 gentoo Linux，读者复现此方案时需要一台任意的 Linux 计算机。Kubernetes 官方网站上存在所有组件的说明和配置方式，也有第三方文档详细描述这里的细节问题，如域名和证书配置，网络方案的选择与配置等细节。

本人出于逐步研究 kubernetes 核心组件的目的，在裸机上配置了 kubernetes 的大多数组件，最后也没有完全完成这些配置。因为这些内容工作量极大并且和本设计的重心无关。达到了了解系统的部署方式这一目标之后就没必要继续了。

% TODO: links

minikube local approach

minikube 是 kubernetes 团队官方提供的一个用于快速部署单机测试集群的工具，其支持所有主流操作系统。事实上，minikube 同时支持 Windows，macOS，Linux 三大平台，因为主要运行在虚拟机中，系统本机的操作系统环境本身不被依赖。几乎所有主流的虚拟机都被支持，包括了 KVM, VirtualBox, HyperV, VMWare Fusion 等。

在一些基本的配置正确的情况下，minikube 可能是最容易成功运行的方式。尽管如此，这个所谓的“开箱即用”也需要环境满足一些基本要求，例如某些平台下，可以运行 docker-machine。

因为虚拟机后端可以被任意替换，minikube 支持将后端配置为 none 从而支持将宿主机直接作为“虚拟机”来使用。这样会对你的宿主机环境添加两个额外的要求：一、你的宿主机需要可用的 docker 服务；二、你需要使用 root 权限运行从而允许 minikube 向宿主系统中安装程序。

此模式的好处是减少了虚拟机的性能开销，且更容易访问运行 kubernetes 的环境，但是对本机的污染和依赖是需要我们付出的代价。

minikube VM approach

这里我们使用一种虚拟机作为后端来启动 minikube 的单机 kubernetes 集群。Linux 平台上的默认选择是 VirtualBox，作为一个开源且免费的优秀虚拟机管理软件，因为优异的跨平台性能被作为了 minikube 在多个平台上的默认的虚拟机后端。但是这里我们选择更加 Linux 友好，功能更强的 KVM 作为后端，进行一次配置尝试。KVM 全名为 Kernel-based Virtual Machine，正如其名，是 Linux 内核支持的虚拟机 Hypervisor。正如上文中描述过，若使用此方式，需要配置内核支持 KVM 的开关。因为内核和 Hypervisor 二合一，效率会更高。同时这也是工业界和云服务提供商常用的虚拟化方式，经受住了考验，因此这里我们选择 KVM 进行实验。

下面我们给出此方式运行 kubernetes 集群的命令与输出，方便读者理解此工具都执行了哪些任务。

% TODO: outputs

\subsubsection{搭建 Kubernetes Operator 开发环境}

在可以连接并管理一个 Kubernetes 集群的前提下，我们可以开发自己的 Operator，并且以某些方式运行我们的 Operator，让它进行决策，并且向 API Server 提交 API 对象以执行我们需要的行为。

Operator Framework 支持包括 golang，Ansible 在内的几种编程语言或工具。这其中 golang 由于靠近 docker，云原生等生态系统，一定会提供，Ansible 架构则是传统集群管理自动化运维的工具，主要推动方是 Redhat，出现在这里也很合乎习惯。为了贴近生态，更容易在 troubleshooting 时获取信息，也为了通用编程语言处理逻辑时的便捷性，本人选择 golang 作为开发语言。

Operator Framework 可以理解为是一套 golang 语言开发的，提供 Operator 基本功能的库。它包装了 leader 选举，程序入口，常用操作 utils 等内容。我们编写的 Operator 逻辑可以在依赖，扩展 Framework 提供的代码的基础上进行。

Operator SDK 是一个命令行工具。上述框架代码的很多细节，手工编写意义不大且容易出错，SDK CLI 可以帮助我们生成。同时当我们为自己的 Operator 添加功能模块时，编写了部分抽象定义的代码，SDK 帮助我们以代码生成的方式生成模版代码，被内部其他逻辑使用。最后，我们编写的代码如果要在 Kubernetes 集群中运行，需要相对而言繁琐一些的编译，构建，制作 docker 镜像等发布流程，而 SDK CLI 可以帮助我们一键式在集群外运行 Operator，与集群交互，极大加快了迭代测试的速度。

下面给出使用 Operator-SDK 时，常用的几个操作如何执行，也方便读者理解系统运行的方式，从而理解本文内容。

%TODO: stdout

\subsubsection{开发调度执行模块}

定义 CRD 与 CR，CRD 为自定义资源定义，给出了我们添加的自定义资源的模板，CR 为自定义资源，是这种定义下的一个实例。利用 OOP 的概念来解释的话，CRD 就是类型 class，CR 就是实例 instance。下面给出本人编写的 yaml 格式的定义以及对应的 golang 数据结构，再解释其释义。

% TODO: code

\subsubsection{开发算法实现}

由上下文给出的分析可知，我们的调度算法是一个纯函数，在给定业务模型定义和服务器节点资源定义后，输出一组编排方式，它的输入与输出都是给定的，下面我们把相关的数据结构定义与函数签名（golang 语法）给出：

% TODO: code

\subsubsection{联调测试}

本部分讲述本设计中在基本完成代码的开发与测试后，如何测试系统能否正常工作，观察效果以及使用方式。



\subsubsection{结果对比}

% TODO: do what here?

\subsubsection{难点与问题}

本部分讲述在实现的过程当中，本人遇到了哪些难以解决的问题，最后又是如何克服的。这部分旨在让读者明白完成一个工程项目比起理论算法研究的不同之处，以及在实现的过程当中本人的时间和精力主要用于解决哪些问题了。

开发环境权限控制

\subsubsection{工程实现细节与亮点}

本部分讲述工程细节中的细节问题和自认为比较亮点的解决方案。

NFS 网络文件系统

嵌套虚拟化与局域网网络空间映射

编排算法至 Kubernetes Deployment 映射

\subsection{算法描述}

本部分讨论在不涉及系统实现的细节前提下，调度算法的背景，意义与实现。

\subsubsection{背景}

本部分讨论一个通用的调度算法需要考虑哪些内容。

我们先思考一下，一个通用的应用程序运行需要依赖哪些资源。资源总共分为软件资源和硬件资源两类。软件资源包括操作系统版本，动态链接库依赖等，这里不在我们的主要讨论范围之内，暂时不考虑。硬件资源包括计算资源，即处理器时间；存储资源，包括主存储器，外置存储器如硬盘容量；网络带宽；异构计算设备，包括，型号，类型，使用率等等限制。

这里定义我们的调度算法为，在软件资源依赖能满足的前提下，将不同的多租户应用部分编排至不同的应用与机器，并保证满足各个租户业务与数据的资源声明得到满足。

为了满足这些资源限定，一个通用的算法需要对可能出现的所有资源类型进行分类，才能从更抽象的角度进行考虑。因为我们无法枚举可能出现的一切资源类型。

一切资源限度要求，都可以用一个标量来描述。如 CPU 计算资源需求，可以将单位核数输出的计算力定义为一个定值，假设就是 100，那么每个应用对 CPU 计算能力的要求就可以使用一个数值来描述了。抽象来讲，即是一个标量加上任意自定义的单位即可描述。

然而考虑到计算资源横向扩展的要求，资源的种类又需要做出区分。考虑内存消耗，对于深度学习模型而言，内存消耗主要是模型加载至内存中，每一台运行服务的服务器都需要消耗等量的内存。再考虑计算资源消耗，对于稳定相同的计算任务或者流量，消耗的总计算力之和不变，横向扩展后新增的服务器不需要额外浪费计算力，而是负担了原有服务器不能承担的一部分任务。我们将前一种横向扩展后每台服务器都要消耗等量的资源称为硬性资源，后一种可以被横向扩展利用的资源称为弹性资源。在绝大多数场景下，如此划分资源就可以描述弹性调度场景下资源的消耗量。

到此为止，我们已经得到了一个通用调度算法的定义，即具有多种资源约束，资源约束都被归类至硬性资源和弹性资源其中之一，同时满足。下文我们开始讨论常用的优化算法，并着重考虑他们在我们场景下的使用方式。

\subsubsection{分析}

在这个背景下，调度算法可以处理如下问题：

算法的输入如下：

有 $N$ 个业务，或称租户，模型，下面统称模型，记为 $Model_1,Model_2,...,Model_N$。每个模型都需要 $a$ 个硬性资源 $Rfix_1,Rfix_2,...,Rfix_a$，$b$ 个弹性资源 $Relastic_1,Relastic_2,...,Relastic_b$。我们还有 $M$ 种机器类型，每种机器类型也需要给出上述硬性资源和弹性资源的提供量 $Rfix_1,Rfix_2,...,Rfix_a,Relastic_1,Relastic_2,...,Relastic_b$。

算法的输出如下：

我们需要给出 $d$ 个部署信息，记为 $Deployment_1,Deployment_2,...,Deployment_d$，每个部署信息包括了其所包含的模型列表以及需要的机器个数，即模型列表和副本数组成的二元组：$([Model_x,Model_y,...,Model_{last}],Replicas)$。

\subsubsection{贪心算法}

贪心算法是一类算法思想的统称，指每一步都选择当前一步考虑范围内的最优解，最终得到的解就是全剧最优解的一类算法。如果放宽条件，广义的贪心算法也就指每一步都选择考虑范围内的最优解的算法。因为在足够复杂的场景内，我们不一定能给出一个调度问题的全局最优解，我们这里的所采用的贪心策略，将使用后一种广义的定义。

在我们的场景下，这个优化问题即是一个这样的组合问题，将模型组合于不同的部署规格之中。

\subsubsection{背包问题}

所谓背包问题，指的是我们具有多个背包，每个背包能承载一定量的重量，背包当中需要存放重量各自不同的物品，我们以一个确定的目标，如使用给定的背包数目和规格装下的物品重量之和最大。

对于调度算法来讲，不考虑动态改变配置的场景下调度动作路径的问题，则可以简化为如下一个问题：

对于异质数据和计算逻辑的部署，我们称呼一份数据和计算模型一致的多副本为一个应用(application)，承载多个相同应用的一组进程副本为集群(cluster)，可见这里的应用就是“物品”，集群就是“背包”，且与上文的讨论相符。

每个应用有多个不同维度的资源，这是比起传统的背包问题的复杂之处，资源可以包括CPU 资源，内存，磁盘存储，网络带宽等多个维度。易知在满足这些要求下的优化问题是 NP 完全问题。这意味着我们无法给出一个确定性的最优的答案，而是使用贪心等算法在可以接受的时间内找到一个较优解。我们甚至不能给出准确的“最优”这一概念的定义。但确定的是，解决各类背包问题的思想在我们的系统开发中都可以得到运用。

如果要给出一个最优的解，我们可以搜索遍历解空间，做一些优化的话，可以利用记忆化搜索以及动态规划的思想加以改进。 %TODO

\subsubsection{总结与展望}

这一部分总结我们采用的算法，以及它的实际表现，以及有哪些不足之处我们还可以改进。

% TODO：enumerate

最终算法

总的来讲，调度问题可以抽象为一个背包问题求解的过程。

增量式调度

我们刚刚描述的算法仅仅完成了从无到有这一步，听起来对于新的业务数据和租户部署来讲，这已经足够了，但是对于一个不能停机，在线上持续提供着服务的集群来讲，这是一个不能接受的逻辑。如果一个不大的变更导致算法重算所有调度结果，使大面积的重分配发生，大量逻辑集群上线与下线发生，服务质量的下降是一个不可接受的事情。因此这里我们需要做一些额外的考虑，避免此类情形发生。为了解决这个问题，我们提出以下三点。

一、降低调度算法的重调度率

对于我们的调度纯函数来讲，增量调度就等于上一次调度输入加上增量补丁后的全部数据再输入调度算法。所以逻辑上不存在“重调度”这个概念。对于重调度的场景，我们可以定义为，两个相差较小的输入各自输出的调度结果的差异。那么这个场景下，我们期望这个差异较小，最好不在边缘数据上有突变。为了达到这个目的，我们可以设法使输入变化时，算法考虑各个模型的顺序变动最少，为了达到这个目的，可以以某种顺序为模型输入排序，也可以要求用户输入额外的数据。

二、使用独立的增量调度算法

kubernetes operator 事实上对于已存在的 CRD 进行变更，变动前后的输入都能获取，这在工程上可以用一些方法实现。对于一个已经初始调度完成的集群，我们的增量调度使用一个独立的算法去完成即可。这里我们可以将变动的每一步拆分开，每一步都进行安全且原子的操作。这里本人暂时没有给出合理的实现，就只提一些思路，不明确描述了。

% TODO: thoughts

三、调度逻辑保证服务持续性

在我们的设计中，算法输出和调度执行拆分为了明确的两个模块，那么我们的执行模块在进行变动时，能进行感知，并且做出考虑，比如在新的部署就绪之前，不下线旧的部署，这样就可以保证服务质量。当然这里有一些其他细节问题，我们就不陷入工程细节，赘述了。

% TODO: rearrange rate

\subsection{效果对比}

本部分我们将人工编排的部署方式，不在服务器重叠多个业务租户，或者小规模的情况下将所有业务租户重叠部署在所有服务器上的情况，和我们的算法给出的结果进行对比。值得注意的是，这里在给定资源和要求的前提下，算法输出可以按照算法模块的输出即可，与执行器的动作无关。我们的对比也仅仅是理论计算为主。对于涉及执行的部分则不能如此。例如实际执行压力测试，观察效果。

\subsubsection{资源利用率}

本部分对比在人工部署，逻辑集群上不堆叠多个业务时，资源利用率和我们的方法相比如何。

\subsubsection{容灾能力}

\subsubsection{性能测试与压力测试}

本部分测试整个系统的抗压能力，不止是算法的理论推导部分。

